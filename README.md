# dbx: A high performance database library for golang supporting KV caching full table data. 

> **dbx = MySQL/Sqlite3 + Memcached**

There's sqlx, gorm... Why build this wheel? 

In my work, I need to deal with a large number of log data (multi-layer nested JSON format, row tens of billions, size TB level data), but also to do business data association with remote DB, and fast query.
Yes, it's very difficult. I urgently need a DB library that can support full table caching (mainly for remote data caching, local TB level can't cache all), supporting nesting of structures, so dbx was born.
Redis, Memcached can also meet the requirements initially, but at the same time, operating cache, DB will be more cumbersome, there will be consistency problems, the code is a lot of verbosity.
So DBX was born. At present, it supports MySQL/Sqlite3, transparently caches data according to rows, and supports nesting of structured bodies freely. It only relies on the following class libraries:
```bash
go get "github.com/go-sql-driver/mysql"
go get "github.com/mattn/go-sqlite3"
```


# Supporting caching, high performance read KV cached full table data
After a simple test (with small data), Sqlite3 can be queried directly at a speed of 3w+/s, and 350 w+/s after opening the cache is much faster than Redis (because it has no network IO).
It then supports caching (generally for small tables, ensuring that memory can be opened when it can be put down)
```golang
db.BindStruct("user", &User{}, true)
db.BindStruct("group", &Group{}, true)
db.EnableCache(true)
```


# Support nesting, avoid inefficient reflection
Golang is a static language. Reflections are often used to implement more complex functions, but they slow down severely when they are not used properly. Practice has found that we should try our best to use digital index instead of string index, such as Field () performance is about 50 times that of FieldByName ().
Most DB libraries do not support nesting because reflection is slow and complex, especially when there are too many nested layers. Fortunately, through hard work, DBX effectively implements the nesting support of unlimited layers, and the performance is good.

```golang
type Human struct {
	Age int64     `db:"age"`
}
type User struct {
	Human
	Uid        int64     `db:"uid"`
	Gid        int64     `db:"gid"`
	Name       string    `db:"name"`
	CreateDate time.Time `db:"createDate"`
}
```


# Graceful API style
by golang's reflective feature, it can achieve the convenience close to script language level. As follows:
```golang

// Open database
db, err = dbx.Open("mysql", "root@tcp(localhost)/test?parseTime=true&charset=utf8")

// insert one
db.Table("user").Insert(u1)

// find one
db.Table("user").WherePK(1).One(u2)

// update one
db.Table("user").Update(u2)

// delete one
db.Table("user").WherePK(1).Delete()

// find multi
db.Table("user").Where("uid>?", 1).All(&userList)

```

# Log output to specified stream
This design should be extended to all complex class libraries.
```golang
// output error information generated by DB to standard output (console)
db.Stderr = os.Stdout

// output the error information generated by DB to the specified file
db.Stderr = dbx.OpenLogFile("./db_error.log") 

// default: redirect the output of DB (mainly SQL statements) to "black hole" (no information such as executed SQL statements is output)
db.Stdout = ioutil.Discard

// default: Output from DB (mainly SQL statements) to standard output (console)
db.Stdout = os.Stdout
```

# Compatible with native methods
Sometimes we need to call the native interface to achieve more complex purposes.
```golang
// customize complex SQL to get a single result (native)
var uid int64
err = db.QueryRow("SELECT uid FROM user WHERE uid=?", 2).Scan(&uid)
if err != nil {
	panic(err)
}
fmt.Printf("uid: %v\n", uid)
db.Table("user").LoadCache() // Customization requires manual refresh of the cache
```

# Use cases
It's so simple that you only need to paste a piece of test code to master its usage:
```golang
package main

import (
	"github.com/mydeeplike/dbx"
	"fmt"
	"os"
	"time"
)

type User struct {
	Uid        int64     `db:"uid"`
	Gid        int64     `db:"gid"`
	Name       string    `db:"name"`
	CreateDate time.Time `db:"createDate"`
}

func main() {

	var err error
	var db *dbx.DB

	// db, err = dbx.Open("sqlite3", "./db1.db?cache=shared&mode=rwc&parseTime=true&charset=utf8") // sqlite3
	db, err = dbx.Open("mysql", "root@tcp(localhost)/test?parseTime=true&charset=utf8")            // mysql
	
	if err != nil {
		panic(err)
	}
	defer db.Close()

	// output to
	db.Stdout = os.Stdout // output sql to os.Stdout
	db.Stderr = dbx.OpenLogFile("./db_error.log") // output error to specified file
	// db.Stdout = ioutil.Discard // default: output sql to black hole

	// argument setting:
	db.SetMaxIdleConns(10)
	db.SetMaxOpenConns(10)
	db.SetConnMaxLifetime(time.Second * 5)

	// create table
	_, err = db.Exec(`DROP TABLE IF EXISTS user;`)
	_, err = db.Exec(`CREATE TABLE user(
		uid        INT(11) PRIMARY KEY AUTO_INCREMENT,
		gid        INT(11) NOT NULL DEFAULT '0',
		name       TEXT             DEFAULT '',
		createDate DATETIME         DEFAULT CURRENT_TIMESTAMP
		);
	`)
	if err != nil {
		panic(err)
	}

	// enable cache, optional, usually only for small tables to enable the cache, more than 10W rows, not recommended to open!
	db.BindStruct("user", &User{}, true)
	db.EnableCache(true)

	// insert one
	u1 := &User{1, 1, "jack", time.Now()}
	_, err = db.Table("user").Insert(u1)
	if err != nil {
		panic(err)
	}

	// read one
	u2 := &User{}
	err = db.Table("user").WherePK(1).One(u2)
	if err != nil {
		panic(err)
	}
	fmt.Printf("%+v\n", u2)

	// update one
	u2.Name = "jack.ma"
	_, err = db.Table("user").Update(u2)
	if err != nil {
		panic(err)
	}

	// delete one
	_, err = db.Table("user").WherePK(1).Delete()
	if err != nil {
		panic(err)
	}
	
	// Where condition + update
	_, err = db.Table("user").WhereM(dbx.M{{"uid", 1}, {"gid", 1}}).UpdateM(dbx.M{{"Name", "jet.li"}})
	if err != nil {
		panic(err)
	}

	// insert multi
	for i := int64(0); i < 5; i++ {
		u := &User{
			Uid: i,
			Gid: i,
			Name: fmt.Sprintf("name-%v", i),
			CreateDate: time.Now(),
		}
		_, err := db.Table("user").Insert(u)
		if err != nil {
			panic(err)
		}
	}

	// fetch multi
	userList := []*User{}
	err = db.Table("user").Where("uid>?", 1).All(&userList)
	if err != nil {
		panic(err)
	}
	for _, u := range userList {
		fmt.Printf("%+v\n", u)
	}

	// multi update
	_, err = db.Table("user").Where("uid>?", 3).UpdateM(dbx.M{{"gid", 10}})
	if err != nil {
		panic(err)
	}

	// multi delete
	_, err = db.Table("user").Where("uid>?", 3).Delete()
	if err != nil {
		panic(err)
	}

	// count()
	n, err := db.Table("user").Where("uid>?", -1).Count()
	if err != nil {
		panic(err)
	}
	fmt.Printf("count: %v\n", n)

	// sum()
	n, err = db.Table("user").Where("uid>?", -1).Sum("uid")
	if err != nil {
		panic(err)
	}
	fmt.Printf("sum(uid): %v\n", n)

	// max()
	n, err = db.Table("user").Where("uid>?", -1).Max("uid")
	if err != nil {
		panic(err)
	}
	fmt.Printf("max(uid): %v\n", n)

	// min()
	n, err = db.Table("user").Where("uid>?", -1).Min("uid")
	if err != nil {
		panic(err)
	}
	fmt.Printf("min(uid): %v\n", n)

	// Customize complex SQL to get a single result (native)
	var uid int64
	err = db.QueryRow("SELECT uid FROM user WHERE uid=?", 2).Scan(&uid)
	if err != nil {
		panic(err)
	}
	fmt.Printf("uid: %v\n", uid)
	db.Table("user").LoadCache() // Customization requires manual refresh of the cache

	// Customize complex SQL to get multiple (native)
	var name string
	rows, err := db.Query("SELECT `uid`, `name` FROM `user` WHERE 1 ORDER BY uid DESC")
	if err != nil {
		panic(err)
	}
	rows.Close()
	for rows.Next() {
		rows.Scan(&uid, &name)
		fmt.Printf("uid: %v, name: %v\n", uid, name)
	}
	db.Table("user").LoadCache() // Customization requires manual refresh of the cache

	return
}

```


[中文文档](README_cn.md)
